{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Web browsing agents with langchain\n",
    "### Setup agent functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install langchain\n",
    "%pip install langchain-community\n",
    "%pip install playwright\n",
    "%pip install tarsier\n",
    "%pip install openai\n",
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# Setup Playwright\n",
    "p = await async_playwright().__aenter__()\n",
    "browser = await p.chromium.launch(headless=False)\n",
    "page = await browser.new_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T08:46:31.531676Z",
     "start_time": "2023-11-11T08:46:31.501731Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "\n",
    "from tarsier import Tarsier, GoogleVisionOCRService\n",
    "# import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv(\"../.env.local\")\n",
    "\n",
    "\n",
    "# Setup Creds\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "with open(\"../.tarsier.json\", \"r\") as f:   \n",
    "    google_cloud_credentials = json.load(f)\n",
    "\n",
    "# Setup Tarsier\n",
    "ocr_service = GoogleVisionOCRService(google_cloud_credentials)\n",
    "tarsier = Tarsier(ocr_service)\n",
    "tag_to_xpath = {}\n",
    "\n",
    "\n",
    "# Define tools/actions\n",
    "@tool\n",
    "async def read_page() -> str:\n",
    "    \"\"\"\n",
    "    Use to read the current state of the page\n",
    "    \"\"\"\n",
    "    return await read_page_impl()\n",
    "\n",
    "\n",
    "async def read_page_impl() -> str:\n",
    "    page_text, inner_tag_to_xpath = await tarsier.page_to_text(page)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    await page.screenshot(path=f'../screenshots/${now}.png')\n",
    "    tag_to_xpath.clear()\n",
    "    tag_to_xpath.update(inner_tag_to_xpath)\n",
    "    return page_text\n",
    "\n",
    "\n",
    "@tool\n",
    "async def click(element_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Click on an element based on element_id and return the new page state\n",
    "    \"\"\"\n",
    "    x_path = tag_to_xpath[element_id]['xpath']\n",
    "    print(x_path)\n",
    "    element = page.locator(x_path)\n",
    "    await element.scroll_into_view_if_needed()\n",
    "    await page.wait_for_timeout(1000)\n",
    "    await element.click()\n",
    "    await page.wait_for_timeout(2000)\n",
    "    return await read_page_impl()\n",
    "\n",
    "\n",
    "@tool\n",
    "async def type_text(element_id: int, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Input text into a textbox based on element_id and return the new page state\n",
    "    \"\"\"\n",
    "    x_path = tag_to_xpath[element_id]['xpath']\n",
    "    print(x_path)\n",
    "    try:\n",
    "        await page.locator(x_path).clear()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    await page.locator(x_path).press_sequentially(text)\n",
    "    return await read_page_impl()\n",
    "\n",
    "\n",
    "@tool\n",
    "async def press_key(key: str) -> str:\n",
    "    \"\"\"\n",
    "    Press a key on the keyboard and return the new page state\n",
    "    \"\"\"\n",
    "    await page.keyboard.press(key)\n",
    "    await page.wait_for_timeout(2000)\n",
    "    return await read_page_impl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GPT4-V + Tarsier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:49:41.232707Z",
     "start_time": "2023-11-11T07:49:41.103809Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = \"\"\"\n",
    "You are a web interaction agent. Use the read page tool to understand where you currently are. \n",
    "You will be passed in OCR text of a web page where element ids are to the left of elements. \n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These were previous tasks you completed:\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Setup chain\n",
    "tarsier_agent_chain = initialize_agent(\n",
    "    [read_page, click, type_text],\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Go to google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.goto(\"https://nextjs-dashboard-nine-phi-61.vercel.app/login\")\n",
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Read the page, log in with username: itaimaoz@gmail.com and password: rze_VKG1ycp0xnv5zry\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Click on Invoices, then create a new invoice\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Enter the following details:\n",
    "    - Customer Name: Lee\n",
    "    - Invoice Amount: 1000\n",
    "    - Invoice Status: Pending\n",
    "\n",
    "    Then submit the form\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Create another invoice with the following details:\n",
    "    - Customer Name: Evil Rabbit\n",
    "    - Invoice Amount: 2000\n",
    "    - Invoice Status: Paid\n",
    "\n",
    "    Then navigate back to the dasahbotd and check that the invoices were created\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Go to Invoices and delete the invoice you created for Evil Rabbit on the previous step\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Search for invoices for Evil Rabbit\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    go back to Invoices. is there an option to search for invoices?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    so search for invoices for Evil Rabbit\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    yes, the invoices appear as you type. so you only need to type the first few letters of the customer name. please search for invoices for Evil Rabbit\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    look at the screen again, and double check whether you see invoices for Evil Rabbit\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Edit the one for $2.00 to $1000.00\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    try again\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.goto(\"https://www.google.com/\")\n",
    "await tarsier_agent_chain.arun(\n",
    "    \"\"\"\n",
    "    Read the page, search for OpenAI Dev day, go to the first video\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "client = vision.ImageAnnotatorClient.from_service_account_info(google_cloud_credentials)\n",
    "\n",
    "with open(\"../screenshots/$2024-10-30_18-48-09.png\", \"rb\") as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "response = client.text_detection(image={\"content\": content})\n",
    "texts = response.text_annotations\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "client = vision.ImageAnnotatorClient.from_service_account_info(google_cloud_credentials)\n",
    "\n",
    "with open(\"../screenshots/Screenshot 2024-10-30 at 19.47.25.jpg\", \"rb\") as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.Image(content=content)\n",
    "\n",
    "\n",
    "response = client.logo_detection(image=image)\n",
    "logos = response.logo_annotations\n",
    "print(\"logos:\")\n",
    "for logo in logos:\n",
    "    print(logo.description)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
